---
title: "Sparse Matrices and Top-Voted Kaggle Kernels"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(Matrix)
library(tidyverse)
library(igraph)
```

We work with the same dataset used for `Tidyverse` containing data regarding some of the top-voted kaggle kernels.

```{r}
kaggle <- read_csv("kagglekernels.csv", col_types = cols(
  Votes=col_double(),
  Owner=col_factor(),
  Kernel=col_factor(),
  Dataset=col_factor(),
  Output=col_character(),
  `Code Type`=col_factor(),
  Language=col_factor(),
  Comments=col_double(),
  Views=col_double(),
  Forks=col_double()
))
kaggle # Tibbles automatically print head(tibble)
```

Again, we can use the `Tags` to create a number of different new variables, each representing one `Tag`. 

```{r, fig.width=15, fig.height=15}
# stop here in order to have the column names
tagmatrix <- kaggle  %>% 
    dplyr::select(Tags) %>%  
    mutate(rn=row_number()) %>%             
    separate_rows(Tags, sep="\\s*,\\s*") %>%  # RegEx comma-separated tags
    mutate(i1=1) %>%                          # Uniquely identifies rows together with rn
    mutate_all(~na_if(., "")) %>%             # remove NA values generated by strings such as "<tag>,"
    pivot_wider(names_from = Tags, 
                values_from = i1,
                values_fill = list(i1 = 0)) %>% # Wide format
    dplyr::select(-rn, -"NA")
tagmatrix
```

Each column now has `1`s where the Kernels were tagged with that specific tag, and `0` otherwise. Data in this form is not very useful for a graph representation. Instead, we can create an adjecency matrix having tags on columns and on rows and where the entries correspond to the number of times the pair of tags was used together in the same kernel. In order to count this metric, we can leverage the `crossprod` function. We also transform `tagmatrix`, which is a `tibble`, into a sparseMatrix.

```{r}
tagmatrix %<>%
  as.matrix %>% 
  Matrix::Matrix(sparse=TRUE) %>% 
  Matrix::crossprod() %>%         # Preserves sparsity
  `diag<-`(0) %>%         # A Tag is not related with itself
  Matrix::drop0()
```

We can look at the sparsity pattern with the function `Matrix::image()` to get an idea of what this matrix looks like.

```{r}
Matrix::image(tagmatrix, main="Sparsity Patter of Tag Pairings")
```

Alternatively, we can look at the percentage of sparsity.
```{r}
nnzero(tagmatrix) / length(tagmatrix)
```

We now proceed to use the `igraph` package to plot a network using `tagmatrix` as a weighted adjecency matrix. Since the matrix is very large, we restrict ourselves to the most "social" tags, i.e. tags that have been paired with other tags more than a given number of times, in this case `5`. To do this, we set those values to zero and then drop the corresponding column and rows (since `tagmatrix` is symmetric).

```{r}
# set values below a threshold to 0
tagmatrix[tagmatrix<=5] <- 0
# drop empty rows and columns for graphing purposes
flag <- apply(tagmatrix, 1, function(x) any(x != 0))
tagmatrix <- tagmatrix[flag, flag]
# value corresponds to how "social" those tags are
graph <- graph_from_adjacency_matrix(tagmatrix, weighted = TRUE)
```

We first choose to plot the network using a standard circle layout.

```{r, fig.width=15, fig.height=15}
plot(graph, layout=layout_in_circle(graph), vertex.label.cex=1.0,
     edge.arrow.size=1.0, vertex.label.color="black", vertex.size=24)
```

While at first this graph looks insightful, it's hard to see some structure. Rather, we can specify a layout by choosing ourselves the coordinates of each node. After some trail and error, it's possible to come up with a layout similar to this one.

```{r, fig.width=15, fig.height=15}
# graph
layout <- matrix(c(0, 1, 1, 0, -1, 2, 3, -1, 3, 4, 4, 1, 1, -1, 2, 0, 3, 4, 4,
                   0, 1, 2, 2,  2, 1, 2,  1, 0, 0, 2, 3, 0,  0, 0, 3, 3, 3, 1), nrow=19, ncol=2)
plot(graph, layout=layout, vertex.label.cex=1.0, edge.arrow.size=1.0, vertex.label.color="black", vertex.size=24)
```

We can see a few important features. First of all it looks like there are three main clusters. One is about _deep learning_, one is about _finance and crime_ data and the other cluster gathers together most other variables. In this latter cluster, we can see that `data visualization` dominates.
